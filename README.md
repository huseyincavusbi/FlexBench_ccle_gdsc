# FlexBench_ccle_gdsc

## Overview

This repository contains a Jupyter Notebook (`FlexBench_ccle_gdsc.ipynb`) designed to benchmark the `flexynesis` multi-omics integration tool. It systematically evaluates different models, data types, and fusion strategies for predicting drug response, specifically focusing on **Paclitaxel** sensitivity using the CCLE (Cancer Cell Line Encyclopedia) and GDSC (Genomics of Drug Sensitivity in Cancer) datasets.

The notebook automates the process of running multiple `flexynesis` experiments, parsing the results, generating comparative visualizations, and analyzing outputs like embeddings and feature importance scores from the best-performing configuration.

## Key Features

*   **Automated Benchmarking:** Runs `flexynesis` with various parameter combinations.
*   **Model Comparison:** Evaluates the performance of `DirectPred`, `supervised_vae`, and `GNN` model architectures.
*   **Data Type Analysis:** Assesses the predictive power of single omics layers (mutation, RNA expression, copy number variation) versus multi-omic combinations.
*   **Fusion Strategy Evaluation:** Compares 'early' and 'intermediate' fusion methods for multi-omic data integration.
*   **GNN Specific Comparison:** For GNN models, compares 'GC' (Graph Convolution) and 'SAGE' (GraphSAGE) convolution types.
*   **Results Aggregation:** Parses `.stats.csv` output files from `flexynesis` runs and aggregates key performance metrics.
*   **Visualization:** Generates boxplots to visually compare performance across different experimental factors.
*   **Ranking:** Ranks experiment configurations based on Pearson Correlation.
*   **Downstream Analysis:** Loads and inspects learned embeddings and feature importance scores from the top-performing experiment.

## Dataset

The benchmark uses pre-processed CCLE and GDSC data. The data includes:
*   Mutation data
*   RNA expression data
*   Copy Number Variation data
*   Clinical data

The dataset can be downloaded and extracted using the command in the first cell of the notebook:
```bash
wget -O - https://bimsbstatic.mdc-berlin.de/akalin/buyar/flexynesis-benchmark-datasets/ccle_vs_gdsc.tgz | tar -xz
```

## Running the Benchmark

1.  **Clone Repository:** Clone this repository to your local machine.
2.  **Setup Environment:** Create and activate a suitable environment and install the dependencies listed above.
3.  **Download Data:** Run the first code cell in `FlexBench_ccle_gdsc.ipynb` to download and extract the dataset into the `ccle_vs_gdsc` directory.
4.  **Execute Notebook:** Run the cells in the `FlexBench_ccle_gdsc.ipynb` notebook sequentially.

## Output

The notebook generates outputs in a directory named `output_improved/` :

*   `output_improved/run_logs/`: Contains detailed log files (`.run.log`) for the standard output and error of each individual `flexynesis` command.
*   `output_improved/plots/`: Stores the generated PNG plots comparing performance.
*   `output_improved/experiment_summary_log.tsv`: A tab-separated file logging the configuration, status, duration, performance metrics, and log file paths for *every* attempted experiment run.
*   `output_improved/aggregated_results.csv`: A processed CSV version of the summary log, ready for analysis.
*   Within `output_improved/`, you will also find files generated by each `flexynesis` run (prefixed by `experiment<N>`):
    *   `.stats.csv`: Performance metrics.
    *   `.embeddings_train.csv` / `.embeddings_test.csv`: Learned sample embeddings.
    *   `.feature_importance.*.csv`: Feature importance scores.
    *   Model checkpoints and other `flexynesis` outputs.

## Results & Interpretation

The notebook includes markdown cells interpreting the generated plots and rankings. Key findings from this specific benchmark run include:

*   **Model Performance:** `supervised_vae` and `GNN` models generally outperform the simpler `DirectPred` model in predicting Paclitaxel response based on Pearson correlation.
*   **Data Type Importance:** RNA expression data appears highly predictive. Models using RNA (either alone or in combination) tend to perform significantly better than those relying solely on mutation or CNV data.
*   **Fusion Strategy:** For multi-omic data, 'intermediate' fusion showed a slight median performance advantage over 'early' fusion in the overall comparison, though the best strategy might be model-dependent.
*   **GNN Layers:** Within GNN models, 'SAGE' convolution layers showed a modest performance edge over standard 'GC' layers.
*   **Top Features:** For the best performing run (`experiment25`: supervised_vae on RNA), Integrated Gradients identified genes like `PLPP2`, `RNASEH2B`, `FLNB`, and `SERPINE1` as highly important for the model's predictions.

## Acknowledgements

This project was inspired by and utilizes code structures from the BIMSB Computational Genomics 2025 course, taught by Dr. Bora Uyar, [https://github.com/BIMSBbioinfo/compgen_course_2025_module3](https://github.com/BIMSBbioinfo/compgen_course_2025_module3)). Thank you to all the instructors and contributors.

This project utilizes the `flexynesis` framework: [https://github.com/BIMSBbioinfo/flexynesis](https://github.com/BIMSBbioinfo/flexynesis)

**Citation for Flexynesis:**
Uyar, B., Savchyn, T., Wurmus, R., Sarigun, A., Shaik, M. M., Franke, V., & Akalin, A. (2024). Flexynesis: A deep learning framework for bulk multi-omics data integration for precision oncology and beyond. *bioRxiv*, 2024.07.16.603606. https://doi.org/10.1101/2024.07.16.603606

## License

This project is licensed under the MIT LICENSE - see the [LICENSE](LICENSE) file for details.
